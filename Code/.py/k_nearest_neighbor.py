# -*- coding: utf-8 -*-
"""k_nearest_neighbor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11CPiMBlM9bT5vc1Ibn6LiOCwZ554-1hp
"""

from collections import Counter
import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score

#Hàm tính khoảng cách Euclidean giữa hai điểm.
def khoang_cach_euclidean(x1, x2):
    return np.sqrt(np.sum((x1 - x2) ** 2))

def duDoan(X_train, y_train, X_test, k):
    list_du_doan = []

    for x_test in X_test:
        list_khoang_cach = []

        for i, x_train in enumerate(X_train):
          #Tính khoảng cách từ điểm test đến điểm train
            khoang_cach = khoang_cach_euclidean(x_test, x_train)
            list_khoang_cach.append((khoang_cach, y_train[i]))

        #Sắp xếp các khoảng cách theo thứ tự tăng dần
        list_khoang_cach.sort(key=lambda x: x[0])

        #Lấy k láng giềng
        k_lang_gieng = list_khoang_cach[:k]

        list_nhan = []
        #Lấy nhãn từ k láng giềng
        for lg in k_lang_gieng:
          nhan = lg[1]
          list_nhan.append(nhan)

        #Đếm số lần xuất hiện của nhãn
        dem_nhan = Counter(list_nhan)
        #Lấy ra cặp dữ liệu xuất hiện nhiều nhất
        cap_pb = dem_nhan.most_common(1)[0]
        #Từ cặp dữ liệu trên, lấy ra nhãn phổ biến nhất
        nhan_pb = cap_pb[0]

        list_du_doan.append(nhan_pb)

    return np.array(list_du_doan)

from google.colab import files
uploaded = files.upload()

data = pd.read_csv("data.csv")
print("Kiểm tra dữ liệu:")
print(data.info())

X = data.iloc[1:,:-1].values
print("\nDữ liệu của X: \n", X);

y = data.iloc[1:,-1].values
print("\nDữ liệu của y: \n", y)

#Xử lý dữ liệu
chuyendoimin_max = preprocessing.MinMaxScaler()
X = chuyendoimin_max.fit_transform(X)
print(X)

k = 10  #Số lượng láng giềng k
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=84)
list_du_doan = duDoan(X_train, y_train, X_test, k)
# print(list_du_doan)
print(list_du_doan)

cm = confusion_matrix(y_test, list_du_doan)
print("\nĐánh giá mô hình qua Confusion Matrix: \n", cm)
print(f"\nMô hình đã dự đoán đúng {cm[1][1]} trường hợp True Positive.")
print(f"Mô hình đã dự đoán đúng {cm[0][0]} trường hợp True Negative.")
print(f"Mô hình đã dự đoán sai {cm[0][1]} trường hợp False Positive.")
print(f"Mô hình đã dự đoán sai {cm[1][0]} trường hợp False Negative.")

print(f"\nĐộ chính xác: {accuracy_score(y_test, list_du_doan)*100:.2f}%")

import matplotlib.pyplot as plt
import seaborn as sns

# Biểu đồ heatmap cho Confusion Matrix KNN
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix - KNN')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

with open("accuracy_knn.txt", "w") as f:
    f.write(str(accuracy_score(y_test, list_du_doan)))

from google.colab import files
files.download("accuracy_knn.txt")